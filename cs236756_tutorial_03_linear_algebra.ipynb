{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img src=\"https://img.icons8.com/dusk/64/000000/mind-map.png\" style=\"height:50px;display:inline\"> CS 236756 - Technion - Intro to Machine Learning\n",
    "#### Tal Daniel\n",
    "## Tutorial 03 - Linear Algebra & SVD\n",
    "\n",
    "* Inspired by slides by Elad Osherov and slides from <a href=\"http://www.mmds.org/\">MMDS</a>\n",
    "\n",
    "### <img src=\"https://img.icons8.com/bubbles/50/000000/checklist.png\" style=\"height:50px;display:inline\"> Agenda\n",
    "\n",
    "* Linear Algebra Refresher\n",
    "* Eigen Values and Vectors Decomposition\n",
    "* Singular Value Decomposition\n",
    "\n",
    "#### <img src=\"https://img.icons8.com/bubbles/50/000000/link.png\" style=\"height:30px;display:inline\"> Useful Resource\n",
    "**<a href=\"http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/3274/pdf/imm3274.pdf\">The Matrix Cookbook</a>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for the tutorial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img src=\"https://img.icons8.com/dusk/50/000000/math.png\" style=\"height:50px;display:inline\"> Linear Algebra Refresher\n",
    "\n",
    "### <img src=\"https://img.icons8.com/nolan/64/000000/circled-up-right-2.png\" style=\"height:50px;display:inline\"> Vectors\n",
    "* Geometric object that has both a magnitude and direction\n",
    "    * $ x = \\begin{bmatrix}\n",
    "           x_{1} \\\\\n",
    "           x_{2} \\\\\n",
    "           \\vdots \\\\\n",
    "           x_{n}\n",
    "         \\end{bmatrix} = (x_1, x_2, ..., x_n)^{T} \\in \\mathcal{R}^n$\n",
    "* Magnitude of a vector: $||x|| = \\sqrt{x^{T}x} = \\sqrt{x_1^2 +x_2^2 +... +x_n^2}$\n",
    "* **Cardinality** of a vector - the number of non zero elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v:\n",
      "[[-16]\n",
      " [  7]\n",
      " [-20]\n",
      " [-10]\n",
      " [ 12]\n",
      " [  6]]\n",
      "v^T:\n",
      "[[-16   7 -20 -10  12   6]]\n",
      "magnitude of v:\n",
      "31.38470965295043\n",
      "cardinality- non zero elements:\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# let's see some vectors\n",
    "v = np.random.randint(low=-20, high=20, size=(6, 1))\n",
    "print(\"v:\")\n",
    "print(v)\n",
    "print(\"v^T:\")\n",
    "print(v.T)\n",
    "print(\"magnitude of v:\")\n",
    "print(np.sqrt(np.sum(np.square(v))))\n",
    "print(\"cardinality- non zero elements:\")\n",
    "print(np.sum(v != 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <img src=\"https://img.icons8.com/color/96/000000/satellites.png\" style=\"height:50px;display:inline\"> Inner Product Space\n",
    "* A mapping $\\langle \\cdot, \\cdot \\rangle : V \\times V \\rightarrow F$ that satisfies:\n",
    "    * Conjucate Symetry: $\\langle x, y \\rangle = \\overline{\\langle y, x \\rangle} $\n",
    "    * Liniearity in the First Argument: \n",
    "        * $\\langle a \\cdot x, y \\rangle = a \\cdot \\langle x, y \\rangle$\n",
    "        * $\\langle x + z, y \\rangle = \\langle x, y \\rangle + \\langle z, y \\rangle$\n",
    "    * Positive-definiteness: \n",
    "        * $\\langle x, x \\rangle \\geq 0$\n",
    "        * $\\langle x, x \\rangle = 0 \\rightarrow x=0$\n",
    "* Common Inner Products:\n",
    "    * Real Vector: $\\langle x, y \\rangle = x^{T} y$\n",
    "    * Real Matrix: $\\langle A, B \\rangle = \\textit{trace}(AB^{T})$\n",
    "    * Random Variables: $\\langle x, y \\rangle = \\mathbb{E}[x \\cdot y]$\n",
    "* Properties of **Dot Product**:\n",
    "    * Distributiveness: \n",
    "        * $(a + b)\\cdot c = a \\cdot c + b \\cdot c$\n",
    "        * $a \\cdot (b+c) = a\\cdot b + a\\cdot c$\n",
    "    * Linearity: $(\\lambda a)\\cdot b= a \\cdot (\\lambda b) = \\lambda(a \\cdot b)$\n",
    "    * Symetry: $a \\cdot b= b\\cdot a$\n",
    "    * Non-Negativity: $\\forall a \\neq 0, a\\cdot a >0 , a \\cdot a =0 \\iff a=0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "b:\n",
      "[[ -6]\n",
      " [  5]\n",
      " [ -8]\n",
      " [ -5]\n",
      " [-10]]\n",
      "a.T.dot(b)=\n",
      "[[-24.]]\n",
      "the same as a.T @ b:\n",
      "[[-24.]]\n",
      "a + 0.5=\n",
      "[[1.5]\n",
      " [1.5]\n",
      " [1.5]\n",
      " [1.5]\n",
      " [1.5]]\n",
      "(a + 2 * a).T @ b\n",
      "[[-72.]]\n",
      "the same as a.T @ b + (2 * a).T @ b\n",
      "[[-72.]]\n"
     ]
    }
   ],
   "source": [
    "# let's see some dot products\n",
    "a = np.ones((5,1))\n",
    "b = np.random.randint(low=-10, high=10, size=(5,1))\n",
    "print(\"a:\")\n",
    "print(a)\n",
    "print(\"b:\")\n",
    "print(b)\n",
    "print(\"a.T.dot(b)=\")\n",
    "print(a.T.dot(b))\n",
    "print(\"the same as a.T @ b:\")\n",
    "print(a.T @ b)\n",
    "print(\"a + 0.5=\")\n",
    "print(a + 0.5)\n",
    "print(\"(a + 2 * a).T @ b\")\n",
    "print((a + 2 * a).T @ b)\n",
    "print(\"the same as a.T @ b + (2 * a).T @ b\")\n",
    "print(a.T @ b + (2 * a).T @ b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <img src=\"https://img.icons8.com/color/48/000000/matrix-desktop.png\" style=\"height:30px;display:inline\"> Outer Product\n",
    "* Let:\n",
    "    * $a = (a_1, a_2, ..., a_n)^{T}$\n",
    "    * $b = (b_1, b_2, ..., b_n)^{T}$\n",
    "* The outer product $ab^{T}$: $$ ab^{T} = \\begin{bmatrix}\n",
    "           a_{1} \\\\\n",
    "           a_{2} \\\\\n",
    "           \\vdots \\\\\n",
    "           a_{n}\n",
    "         \\end{bmatrix} [b_1, b_2, ..., b_n] = \\begin{pmatrix}\n",
    "  a_1 b_1 & a_1 b_2 & \\cdots & a_1 b_n \\\\\n",
    "  a_2 b_1 & a_2 b_2 & \\cdots & a_2 b_n \\\\\n",
    "  \\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n",
    "  a_n b_1 & a_n b_2 & \\cdots & a_n b_n\n",
    " \\end{pmatrix} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      "[[0.90266288]\n",
      " [0.94672242]\n",
      " [0.6097391 ]\n",
      " [0.82390305]\n",
      " [0.887672  ]]\n",
      "b:\n",
      "[[0.17321164]\n",
      " [0.658294  ]\n",
      " [0.28232724]\n",
      " [0.52144122]\n",
      " [0.47426751]]\n",
      "outer product: a @ b.T = \n",
      "[[0.15635172 0.59421756 0.25484632 0.47068563 0.42810367]\n",
      " [0.16398334 0.62322169 0.26728553 0.49366009 0.44899968]\n",
      " [0.10561391 0.40138759 0.17214596 0.3179431  0.28917944]\n",
      " [0.1427096  0.54237044 0.23261027 0.42961701 0.39075045]\n",
      " [0.15375512 0.58434916 0.25061399 0.46286877 0.42099399]]\n"
     ]
    }
   ],
   "source": [
    "# outer product\n",
    "a = np.random.random(size=(5,1))\n",
    "print(\"a:\")\n",
    "print(a)\n",
    "b = np.random.random(size=(5,1))\n",
    "print(\"b:\")\n",
    "print(b)\n",
    "ab_t = a @ b.T\n",
    "print(\"outer product: a @ b.T = \")\n",
    "print(ab_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <img src=\"https://img.icons8.com/nolan/64/000000/resize-four-directions.png\" style=\"height:50px;display:inline\"> Vector Norms\n",
    "* A norm on a vector sapce $\\Omega$ is a function $f: \\Omega \\rightarrow \\mathcal{R}$ with the following properties:\n",
    "    * Positive Scalability: $f(ax) = |a|f(x)$\n",
    "    * Triangle Inequality: $f(x+y) \\leq f(x) + f(y)$\n",
    "    * If $f(x) = 0 \\rightarrow x = 0$\n",
    "* $l_1$ norm: $||x||_1 = \\sum_{i=1}^n |x_i| $\n",
    "* $l_2$ norm: $||x||_2 = \\sqrt{\\sum_{i=1}^n |x_i|^2} $\n",
    "    * For **Vectors**: $||x||_2 = x^{T}x$\n",
    "    * $l_2$-distance: $||x -y||_2^2 = (x-y)^{T}(x-y)= ||x||_2^2 -2x^{T}y + ||y||_2^2$\n",
    "* $l_p$ norm: $||x||_p = (\\sum_{i=1}^n |x_i|^p)^{\\frac{1}{p}} $\n",
    "* $l_{\\infty}$ norm: $||x||_{\\infty} = \\max{(|x_1|, |x_2|, ..., |x_n|)} $\n",
    "\n",
    "<img src=\"./assets/tut_03_norm.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      "[[0.21816978]\n",
      " [0.0166349 ]\n",
      " [0.77464535]\n",
      " [0.57721965]\n",
      " [0.1185309 ]]\n",
      "l-1 norm: \n",
      "1.7052005805479906\n",
      "l-2 norm: \n",
      "0.997588236132957\n",
      "l-infinity norm:\n",
      "0.7746453522517625\n",
      "b:\n",
      "[[0.08994736]\n",
      " [0.29621743]\n",
      " [0.17487165]\n",
      " [0.40283392]\n",
      " [0.15783109]]\n",
      "l-2 distance between a and b:\n",
      "[[0.69734551]]\n"
     ]
    }
   ],
   "source": [
    "# norms and distance\n",
    "a = np.random.random(size=(5,1))\n",
    "print(\"a:\")\n",
    "print(a)\n",
    "print(\"l-1 norm: \")\n",
    "print(np.sum(abs(a)))\n",
    "print(\"l-2 norm: \")\n",
    "print(np.sqrt(np.sum(np.square(a))))\n",
    "print(\"l-infinity norm:\")\n",
    "print(np.max(abs(a)))\n",
    "b = np.random.random(size=(5,1))\n",
    "print(\"b:\")\n",
    "print(b)\n",
    "print(\"l-2 distance between a and b:\")\n",
    "print(np.sqrt((a - b).T @ (a - b)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <img src=\"https://img.icons8.com/bubbles/100/000000/groups.png\" style=\"height:50px;display:inline\"> Linear Dependency\n",
    "* Given a set of vectors $X =\\{x_1, x_2, ..., x_n \\}$, a **linear combination** of vectors is written as:\n",
    "$$ ax = a_1 x_1 + a_2 x_2 + ... +a_n x_n $$\n",
    "* $x_i \\in X$ is **linearly dependent** if it can be written as linear combination of $X \\setminus \\{x_i\\}$\n",
    "\n",
    "<img src=\"./assets/tut_03_linear_dep.jpg\" style=\"height:200px\">\n",
    "\n",
    "### <img src=\"https://img.icons8.com/dusk/64/000000/lego.png\" style=\"height:50px;display:inline\"> Basis\n",
    "* A basis is a **linearly independent** set of vectors that spans the \"whole sapce\"\n",
    "* Every vector in the space can be written as a linear combination of vectors in the basis\n",
    "    * For example, **the standard basis (unit vectors)**: $\\{e_i \\in \\mathcal{R}^n | e_i =(0, 0, ..., 0, 1,0, ..., 0)^{T}\\}$ \n",
    "        * $x^{T} = (3 ,2 ,5)^{T} = 3(1,0,0)^{T}+2(0,1,0)^{T}+5(0,0,1)^{T} = 3e_1^T +2e_2^T +5e_3^T$\n",
    "* **Projection** of a vector: $x\\cdot e_i = x^T e_i = e_i^T x$\n",
    "* The basis vectors suffice:\n",
    "    * Orthogonal - $e_i^T e_j = 0$\n",
    "    * Normalized - $e_i^T e_i = 1$\n",
    "    * Orthogonal + Normalized = Orthonormal\n",
    "    * If $A$ is **orthogonal** then:\n",
    "        * $A$ is a square matrix\n",
    "        * The columns of $A$ are **orthonormal** vectors\n",
    "        * $A^TA = AA^T = I \\rightarrow A^T= A^{-1}$\n",
    "* **Change of Basis** - suppose that we have a basis not necessarily orthonormal $B=\\{b_1, b_2, ..., b_n\\}, b_i \\in \\mathcal{R}^m $\n",
    "    * Vector in the **new** basis is represented with a **matrix-vector** multiplication\n",
    "    * The Identity matrix $I$ maps a vector to itself\n",
    "    * Basis change can be decomposed to: **rotation** matrix and **scale** matrix\n",
    "    * Using an **orthonormal** basis means only a **rotation** around the origin\n",
    "    * **Gram-Schmidt Orthonormaliztion Process**: <a href=\"https://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process\">Link</a>\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/e/ee/Gram-Schmidt_orthonormalization_process.gif\">\n",
    "   By <a href=\"//commons.wikimedia.org/wiki/User:Kieff\" class=\"mw-redirect\" title=\"User:Kieff\">Lucas V. Barbosa</a> - <span class=\"int-own-work\" lang=\"en\">Own work</span>, Public Domain, <a href=\"https://commons.wikimedia.org/w/index.php?curid=24396471\">Link</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V:\n",
      "[[3. 2.]\n",
      " [1. 2.]]\n",
      "U:\n",
      "[[0.9486833  0.70710678]\n",
      " [0.31622777 0.70710678]]\n"
     ]
    }
   ],
   "source": [
    "# Gram-Schmidt Algorithm\n",
    "def gram_schmidt(V):\n",
    "    \"\"\"\n",
    "    Implements Gram-Schmidt Orthonormaliztion Process.\n",
    "    Parameters:\n",
    "        V - matrix such that each column is a vector in the original basis\n",
    "    Returns:\n",
    "        U - matrix with orthonormal vectors as columns\n",
    "    \"\"\"\n",
    "    n, k = np.array(V, dtype=np.float).shape  # get dimensions\n",
    "    # initialize U matrix\n",
    "    U = np.zeros_like(V, dtype=np.float)\n",
    "    U[:,0] = V[:,0] / np.sqrt(V[:,0].T @ V[:,0])\n",
    "    for i in range(1, k):\n",
    "        U[:,i] = V[:,i]\n",
    "        for j in range(i - 1):\n",
    "            U[:,i] = U[:,i] - ((U[:,i].T @ U[:,j]) / (U[:,j].T @ U[:,j])) * U[:, j]\n",
    "        # normalize\n",
    "        U[:,i] = U[:,i] / np.sqrt(U[:,i].T @ U[:,i])\n",
    "    return U\n",
    "\n",
    "v1 = [3.0, 1.0]\n",
    "v2 = [2.0, 2.0]\n",
    "v = np.stack((v1, v2), axis=1)\n",
    "print(\"V:\")\n",
    "print(v)\n",
    "U = gram_schmidt(v)\n",
    "print(\"U:\")\n",
    "print(U)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <img src=\"https://img.icons8.com/bubbles/50/000000/services.png\" style=\"height:50px;display:inline\"> Matrix Operations\n",
    "* Addition\n",
    "    * Commutative: $A + B = B +A$\n",
    "    * Associative: $(A+B) + C = A + (B+C)$\n",
    "* Multiplication - **PAY ATTENTION TO DIMENSTIONS**\n",
    "    * Associative: $A(BC) = (AB)C$\n",
    "    * Distributive: $A(B+C) = AB + AC$\n",
    "    * Non-comutative (**!**): $AB \\neq BA$\n",
    "* Transpose\n",
    "    * $(A^{T})_{ij}$\n",
    "    * $(A^{T})^T = A$\n",
    "    * $(AB)^{T} = B^{T}A^{T}$\n",
    "* Inverse - **MAKE SURE CONDITIONS APPLY**\n",
    "    * **Positive Semi-definite (PSD)** - Matrix $M$ is called *PSD* if for every non-zero column vector $z$, the scalar $z^T M z \\geq 0$\n",
    "    * **Every positive definite matrix is invertible** and its inverse is also positive definite\n",
    "    * $(A^{-1})^{-1} = A$\n",
    "    * $(AB)^{-1} = B^{-1} A^{-1}$\n",
    "    * $(A^T)^{-1} = A^{-T}$\n",
    "    * Inverse of 2x2 matrix: check tutorial 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "[[0.98463396 0.45447991 0.49365401 0.24064992 0.54808428]\n",
      " [0.42278911 0.83835018 0.39599129 0.73846631 0.63763384]\n",
      " [0.35294769 0.00152597 0.9388472  0.31903281 0.2760794 ]\n",
      " [0.82842935 0.64966235 0.40236603 0.47731957 0.12382832]\n",
      " [0.93792802 0.43518515 0.46486903 0.2144443  0.12089541]]\n",
      "inverse of A:\n",
      "[[  3.53324514  -2.98005006   0.1124123    5.56530918  -6.2575821 ]\n",
      " [ -6.92616274   5.94500258  -1.5250271  -11.61645075  15.42540149]\n",
      " [ -4.03894987   2.89078871   0.56121474  -6.69081739   8.63550628]\n",
      " [  6.13826919  -5.40661561   1.42528243  14.0146561  -16.92165325]\n",
      " [  2.16302225   0.19417892  -0.06865877  -0.49267226  -1.89727223]]\n"
     ]
    }
   ],
   "source": [
    "# inverse\n",
    "A = np.random.rand(5, 5)\n",
    "print(\"A:\")\n",
    "print(A)\n",
    "print(\"inverse of A:\")\n",
    "print(np.linalg.inv(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <img src=\"https://img.icons8.com/color/96/000000/master-sergeant-msg.png\" style=\"height:50px;display:inline\"> Matrix Rank\n",
    "* The rank of a matrix is the **maximal number of linearly independent** columns or rows of a matrix\n",
    "* $ A \\in \\mathcal{R}^{m \\times n} \\rightarrow \\textit{rank}(A) \\leq \\min(m,n)$\n",
    "* $\\textit{rank}(A) = \\textit{rank}(A^T)$\n",
    "* $\\textit{rank}(A^T A) = \\textit{rank}(A)$\n",
    "* $\\textit{rank}(A + B) \\leq \\textit{rank}(A) + \\textit{rank}(B)$\n",
    "* $\\textit{rank}(AB) \\leq \\min(\\textit{rank}(A), \\textit{rank}(B))$\n",
    "* A is **full rank** if $\\textit{rank}(A) = \\min(m,n)$\n",
    "* **Singular Matrix** - has dependent rows (and at least one zero eigen-value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "[[1 0 1 3 1]\n",
      " [2 0 1 0 0]\n",
      " [1 2 3 0 3]\n",
      " [1 3 1 3 3]\n",
      " [1 3 3 3 1]]\n",
      "rank(A):\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "A = np.random.randint(low=0, high=4, size=(5,5))\n",
    "print(\"A:\")\n",
    "print(A)\n",
    "print(\"rank(A):\")\n",
    "print(np.linalg.matrix_rank(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <img src=\"https://img.icons8.com/dusk/64/000000/radar.png\" style=\"height:50px;display:inline\"> Range & Nullspace\n",
    "* **Range** (of a matrix) - the span of the columns of the matrix, denoted by the set: $$\\mathcal{R}(A) = \\{y|y= Ax\\} $$\n",
    "* **Nullspace** (of a matrix) - the set of vectors that when multiplied by the matrix result in 0, given by the set: $$\\mathcal{N}(A) = \\{x|Ax=0\\} $$\n",
    "\n",
    "### <img src=\"https://img.icons8.com/dusk/64/000000/radar.png\" style=\"height:50px;display:inline\"> Determinant\n",
    "Let $A = \\begin{pmatrix}\n",
    "  x_1 & y_1 & z_1 \\\\\n",
    "  x_2 & y_2 & z_2 \\\\\n",
    "  x_3 & y_3 & z_3\n",
    " \\end{pmatrix} $, a **square matrix**, then:\n",
    "* $det(A) = |A| = \\begin{vmatrix}\n",
    "  x_1 & y_1 & z_1 \\\\\n",
    "  x_2 & y_2 & z_2 \\\\\n",
    "  x_3 & y_3 & z_3\n",
    " \\end{vmatrix} = x_1 \\begin{vmatrix}\n",
    "  y_1 & z_2 \\\\\n",
    "  y_3 & z_3\n",
    " \\end{vmatrix} -x_2 \\begin{vmatrix}\n",
    "  y_1 & z_1 \\\\\n",
    "  y_3 & z_3 \n",
    " \\end{vmatrix} +x_3\\begin{vmatrix}\n",
    "  y_1 & z_1\\\\\n",
    "  y_2 & z_2 \n",
    " \\end{vmatrix} = x_1 (y_2z_3 - z_2 y_3) -x_2(y_1z_3 - z_1y_3) +x_3(y_1z_2 - z_1 y_2) $\n",
    "* $det(A) = 0 \\iff A$ is **singular** (at least one eigen-value is zero)\n",
    "* If $A$ is diagonal, then $det(A)$ is the prodcut of the diagonal elements (the eigen-values)\n",
    "* $det(AB) = det(A)det(B)$\n",
    "* $det(A^{-1}) = det(A)^{-1}$\n",
    "* $det(\\lambda A) = \\lambda^n det(A)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "[[ 1.4792694  -0.56204891 -0.57136075 -2.1527347   0.79861811]\n",
      " [ 0.37725727 -0.11402182  0.55368031 -0.17979957 -0.3096385 ]\n",
      " [-0.78610946 -0.06434369  0.12422531  0.14632316  0.79623484]\n",
      " [ 0.69049244 -0.84221851 -0.60109636  0.40418209  0.88894044]\n",
      " [-0.24910082 -1.3595816   0.20798817 -1.35291227  1.21427935]]\n",
      "det(A):\n",
      "-2.3388728660269216\n"
     ]
    }
   ],
   "source": [
    "# determinant\n",
    "A = np.random.randn(5,5)\n",
    "print(\"A:\")\n",
    "print(A)\n",
    "print(\"det(A):\")\n",
    "print(np.linalg.det(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img src=\"https://img.icons8.com/dusk/64/000000/fine-print.png\" style=\"height:50px;display:inline\"> Solve Linear Equation Analytically\n",
    "* Definitions:\n",
    "    * $A \\in \\mathcal{R}^{n \\times n}$\n",
    "    * $x, b \\in \\mathcal{R}^{n \\times 1}$\n",
    "* The problem: find the solution of $Ax = b$\n",
    "* Solution: if $A$ is PSD (and thus invertible), then $x = A^{-1} b$\n",
    "* What if $A \\in \\mathcal{R}^{m \\times n}$, $x \\in \\mathcal{R}^{n \\times 1}$, $b \\in \\mathcal{R}^{m \\times 1}$ ?\n",
    "    * $A$ is no longer invertible!\n",
    "* The problem redefined: find $x$ that minimzes the distance from $Ax$ to $b$, or more formally: $$ \\underset{x}{\\mathrm{argmin}} ||Ax - b ||_2^2$$ (also called **least-squares** solution)\n",
    "\n",
    "### <img src=\"https://img.icons8.com/dusk/64/000000/alarm.png\" style=\"height:50px;display:inline\"> Reminder (Tutorial 01) - Vector & Matrix Derivatives\n",
    "\n",
    "* $\\nabla_x Ax = A^{T}$\n",
    "* $\\nabla_x x^{T} A x = (A + A^{T}) x$ \n",
    "* $\\frac{\\partial}{\\partial A} \\ln |A| = A^{-T}$\n",
    "* $\\frac{\\partial}{\\partial A} Tr[AB] = B^{T}$\n",
    "\n",
    "### <img src=\"https://img.icons8.com/dusk/64/000000/task.png\" style=\"height:50px;display:inline\"> Exercise 1 - Least-Squares Solution\n",
    "Given $A \\in \\mathcal{R}^{m \\times n}$, $x \\in \\mathcal{R}^{n \\times 1}$, $b \\in \\mathcal{R}^{m \\times 1}$\n",
    "\n",
    "Find $x$ that minimzes the distance from $Ax$ to $b$, or more formally: $$ \\underset{x}{\\mathrm{argmin}} ||Ax - b ||_2^2$$\n",
    "\n",
    "### <img src=\"https://img.icons8.com/dusk/64/000000/idea.png\" style=\"height:50px;display:inline\"> Solution 1\n",
    "$$ ||Ax - b ||_2^2 = (Ax-b)^T (Ax-b) = x^TA^TAx -x^TA^Tb-b^TAx +b^Tb $$\n",
    "$$\\frac{\\partial ||Ax - b ||_2^2}{\\partial x} = 2A^TAx-2A^Tb = 0 \\rightarrow x = (A^TA)^{-1}A^Tb $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "[[-4  0 -1 -1]\n",
      " [ 0  3  6 -4]\n",
      " [-2  5  1 -4]\n",
      " [ 2  2  3  2]\n",
      " [ 6 -3 -4  2]]\n",
      "b:\n",
      "[[ 0]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-9]\n",
      " [-4]]\n",
      "Least Squares solution for x:\n",
      "[[-0.59465397]\n",
      " [-1.76026098]\n",
      " [ 0.1814853 ]\n",
      " [-1.55940215]]\n"
     ]
    }
   ],
   "source": [
    "# Least Squares Solution\n",
    "m = 5\n",
    "n = 4\n",
    "A = np.random.randint(low=-5, high=10, size=(m,n))\n",
    "b = np.random.randint(low=-10, high=3, size=(m,1))\n",
    "print(\"A:\")\n",
    "print(A)\n",
    "print(\"b:\")\n",
    "print(b)\n",
    "print(\"Least Squares solution for x:\")\n",
    "x = np.linalg.inv(A.T @ A) @ A.T @ b\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img src=\"https://img.icons8.com/bubbles/50/000000/calculator.png\" style=\"height:50px;display:inline\"> Solve Linear Equation Non-Analytically\n",
    "###  <img src=\"https://img.icons8.com/office/80/000000/person-in-a-mirror.png\" style=\"height:50px;display:inline\"> Eigenvalues and Eigenvectors\n",
    "* Definition: Matrix $A$ with **Eigenvalue** $\\lambda \\in \\mathbb{C}$ and **Eigenvector** $x \\in \\mathbb{C}^n$ if $$Ax=\\lambda, x \\neq 0 $$\n",
    "* Finding eigenvalues and eigenvectors\n",
    "    * Find eigenvalues by finding the roots of the polynomial generated by: $$det(\\lambda I -A) = |\\lambda I -A| =0 $$\n",
    "    * For each eigenvalue $\\lambda$, find its corresponding eigenvector $x$ by solving: $$ Ax = \\lambda x$$\n",
    "* Example: $M = \\begin{pmatrix}\n",
    "  2 & 1 \\\\\n",
    "  1 & 2\n",
    " \\end{pmatrix} \\rightarrow |\\lambda I -M| =  \\begin{vmatrix}\n",
    "  2 - \\lambda & 1 \\\\\n",
    "  1 & 2 - \\lambda\n",
    " \\end{vmatrix}  = 3 - 4 \\lambda + \\lambda^2 \\rightarrow \\lambda_{1,2} = 1, 3 \\rightarrow x_{\\lambda = 1}= \\begin{bmatrix}\n",
    "  1 \\\\\n",
    "  -1\n",
    " \\end{bmatrix} , x_{\\lambda=3} = \\begin{bmatrix}\n",
    "  1 \\\\\n",
    "  1\n",
    " \\end{bmatrix}$\n",
    " \n",
    "* Eigenvalues Properties\n",
    "    * $det(\\Lambda) = |\\Lambda| = \\prod_{i=1}^n \\lambda_i$\n",
    "    * $\\textit{rank}(A) = \\sum_{i=1}^n \\mathbb{1}_{\\lambda_i \\neq 0}$\n",
    "    * Eigenvalues of a **diagonal** matrix are the diagonal entries\n",
    "    * A (square) matrix is said to be **diagonalizable** if it can be rewritten as: $A = X \\Lambda X^{-1}$\n",
    "* Eigenvalues of **Symmetric Matrices**:\n",
    "    * Eigenvalues are **real**\n",
    "    * Eigenvectors of **real symmetric** matrices are orthonormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "[[-4  3  7  5 -3]\n",
      " [-6  0 -7  1  5]\n",
      " [-3  6  8 -2  0]\n",
      " [-3  6  8  1  0]\n",
      " [ 6 -7 -3  4  1]]\n",
      "eigenvalues:\n",
      "[ 2.15100061+11.82247774j  2.15100061-11.82247774j\n",
      " -3.962019   +0.j          3.96421735 +0.j\n",
      "  1.69580043 +0.j        ]\n",
      "eigenvectors:\n",
      "[[-0.12167344+0.41100288j -0.12167344-0.41100288j -0.70317398+0.j\n",
      "   0.32865106+0.j         -0.33260964+0.j        ]\n",
      " [-0.20633163-0.48388658j -0.20633163+0.48388658j -0.67589276+0.j\n",
      "   0.26261661+0.j         -0.71850371+0.j        ]\n",
      " [-0.30325931+0.18124115j -0.30325931-0.18124115j  0.17977307+0.j\n",
      "   0.14085581+0.j          0.37207149+0.j        ]\n",
      " [-0.25200678+0.25451382j -0.25200678-0.25451382j  0.10230715+0.j\n",
      "   0.57910496+0.j         -0.48379021+0.j        ]\n",
      " [ 0.53521396+0.j          0.53521396-0.j         -0.07700792+0.j\n",
      "   0.68397228+0.j         -0.02516122+0.j        ]]\n"
     ]
    }
   ],
   "source": [
    "# eigenvalues and eigenvectors\n",
    "A = np.random.randint(low=-10, high=10, size=(5,5))\n",
    "eig, vec = np.linalg.eig(A)\n",
    "print(\"A:\")\n",
    "print(A)\n",
    "print(\"eigenvalues:\")\n",
    "print(eig)\n",
    "print(\"eigenvectors:\")\n",
    "print(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img src=\"https://img.icons8.com/doodle/96/000000/big-puzzle.png\" style=\"height:50px;display:inline\"> Eigen Decomposition\n",
    "* **Eigen-decomposition** (also **spectral decomposition**) - factorization of a matrix into a canonical form, that is, the matrix is represented in terms of its **eigenvalues and eigenvectors**.\n",
    "* **Only** diagonalizable matrices can be factorized\n",
    "* Formally:\n",
    "    * Denote $\\Lambda$ as a matrix with eigenvalues on the diagonal\n",
    "    * Denote $Q$ as a matrix where the columns are the eigenvectors\n",
    "    * Let $A$ be a square $n \\times n$ matrix with $N$ linearly **independent** columns. Then $A$ can factorized as: $$A = Q \\Lambda Q^{-1} $$\n",
    "    \n",
    "# <img src=\"https://img.icons8.com/bubbles/100/000000/question-mark.png\" style=\"height:50px;display:inline\"> What If A Is Non-Square?\n",
    "\n",
    "## <img src=\"https://img.icons8.com/dusk/64/000000/data-sheet.png\" style=\"height:50px;display:inline\"> Singular Value Decomposition (SVD)\n",
    "* In linear algebra, the singular-value decomposition (SVD) is a factorization of a real or complex matrix. It is the generalization of the eigendecomposition of a positive semidefinite normal matrix (for example, a symmetric matrix with positive eigenvalues) to any $ m\\times n$ matrix via an extension of the polar decomposition.\n",
    "* Definition: $$ A_{[m \\times n]} = U_{[m \\times r]} \\Sigma_{[r \\times r]} (V_{[n \\times r]})^T $$\n",
    "* **$A$** - Input Data matrix\n",
    "    * $m \\times n$ matrix (e.g. $m$ documents and $n$ terms that can appear in each document)\n",
    "* **$U$** - Left Singular vectors\n",
    "    * $m \\times r$ matrix (e.g. $m$ documents and $r$ concepts)\n",
    "    * $U = eig(AA^T)$\n",
    "* **$\\Sigma$** - Singular values\n",
    "    * $r \\times r$ **diagonal** matrix (strength of each 'concept')\n",
    "    * $r$ represnts the **rank** of matrix $A$\n",
    "    * $\\Sigma = diag(eigenvalues(A))$\n",
    "* **$V$** - Right Singular vectors\n",
    "    * $n \\times r$ matrix (e.g. $n$ terms and $r$ concepts)\n",
    "    * $V = eig(A^TA)$\n",
    "* Illustration:\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/e/e9/Singular_value_decomposition.gif\">\n",
    "    First, we see the unit disc in blue together with the two canonical unit vectors. We then see the action of M, which distorts the disk to an ellipse. The SVD decomposes M into three simple transformations: an initial rotation $V^{*}$, a scaling $\\Sigma$ along the coordinate axes, and a final rotation $U$. The lengths $\\sigma_1$ and $\\sigma_2$ of the semi-axes of the ellipse are the singular values of $M$, namely $\\Sigma_{1,1}$ and $\\Sigma_{2,2}$.\n",
    "    \n",
    "    By <a href=\"//commons.wikimedia.org/wiki/User:Kieff\" class=\"mw-redirect\" title=\"User:Kieff\">Kieff</a> - <span class=\"int-own-work\" lang=\"en\">Own work</span>, Public Domain, <a href=\"https://commons.wikimedia.org/w/index.php?curid=11416486\">Link</a>\n",
    "    \n",
    "* Another way to look at SVD: $$ A \\approx U\\Sigma V^T = \\sum_i \\sigma_i u_i \\circ v_i^T $$ \n",
    "    <img src='./assets/tut_03_svd_1.jpg' style=\"height:200px\"> <img src='./assets/tut_03_svd_2.jpg' style=\"height:200px\">\n",
    "    \n",
    "* **SVD Properties**\n",
    "    * It is **always** possible to decompose a **real** matrix $A$ to $A = U\\Sigma V^T$ where\n",
    "        * $U, \\Sigma, V$ are **uniuqe**\n",
    "        * $U, V$ are column **orthonormal**\n",
    "            * $U^T U = I, V^T V = I$\n",
    "        * $\\Sigma$ is **diagonal**\n",
    "            * Entries (the singular values) are positive and **sorted** in decreasing order ($\\sigma_1 \\geq \\sigma_2 \\geq ... \\geq 0$)\n",
    "    * <a href=\"http://www.mpi-inf.mpg.de/~bast/ir-seminar-ws04/lecture2.pdf![image.png](attachment:image.png)\">Proof of uniqueness</a>\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c8/Singular_value_decomposition_visualisation.svg/800px-Singular_value_decomposition_visualisation.svg.png\" style=\"height:200px\">\n",
    "(Image from <a href=\"https://en.wikipedia.org/wiki/Singular_value_decomposition\">Wikipedia</a>)\n",
    "\n",
    "### <img src=\"https://img.icons8.com/dusk/64/000000/cinema-.png\" style=\"height:50px;display:inline\"> SVD Example - Users-to-Movies\n",
    "We are given a dataset of user's rating (1 to 5) for several movies of 3 genres (concepts) and we wish to use SVD to decompose to the following componnets:\n",
    "* User-to-Concept - which genres the users prefer: $U$ matrix\n",
    "* Concepts - what is the strength of each genre in the dataset: $\\Sigma$ - strength of each concept (the singular values)\n",
    "* Movie-to-Concept - for each movie, what genres are the most dominant: $V$ matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-to-Movies matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Matrix</th>\n",
       "      <th>Alien</th>\n",
       "      <th>Serenity</th>\n",
       "      <th>Casablanca</th>\n",
       "      <th>Amelie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User 1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Matrix  Alien  Serenity  Casablanca  Amelie\n",
       "User 1       1      1         1           0       0\n",
       "User 2       3      3         3           0       0\n",
       "User 3       4      4         4           0       0\n",
       "User 4       5      5         5           0       0\n",
       "User 5       0      2         0           4       4\n",
       "User 6       0      0         0           5       5\n",
       "User 7       0      1         0           2       2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset and create a pandas DataFrame\n",
    "u_t_m = np.array([[1,1,1,0,0], [3,3,3,0,0], [4,4,4,0,0], [5,5,5,0,0], [0,2,0,4,4], [0,0,0,5,5], [0,1,0,2,2]])\n",
    "print(\"User-to-Movies matrix:\")\n",
    "# print(u_t_m)\n",
    "u_t_m_df = pd.DataFrame(u_t_m, columns=['Matrix', 'Alien', 'Serenity', 'Casablanca', 'Amelie'],\n",
    "                        index=['User 1', 'User 2','User 3', 'User 4', 'User 5', 'User 6', 'User 7'])\n",
    "u_t_m_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U of size (7, 3) :\n",
      "[[-0.1376   0.0236   0.01081]\n",
      " [-0.4128   0.07086  0.03244]\n",
      " [-0.5503   0.0944   0.04324]\n",
      " [-0.688    0.11804  0.05405]\n",
      " [-0.1528  -0.5913  -0.654  ]\n",
      " [-0.0722  -0.7314   0.678  ]\n",
      " [-0.0764  -0.2957  -0.327  ]]\n",
      "Singular values:\n",
      "[12.484  9.51   1.346]\n",
      "as a matrix:\n",
      "[[12.484  0.     0.   ]\n",
      " [ 0.     9.51   0.   ]\n",
      " [ 0.     0.     1.346]]\n",
      "V of size (3, 5) :\n",
      "[[-0.5625  -0.593   -0.5625  -0.09015 -0.09015]\n",
      " [ 0.1266  -0.02878  0.1266  -0.6953  -0.6953 ]\n",
      " [ 0.4097  -0.8047   0.4097   0.09125  0.09125]]\n",
      "reconstruction of user-to-movie:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Matrix</th>\n",
       "      <th>Alien</th>\n",
       "      <th>Serenity</th>\n",
       "      <th>Casablanca</th>\n",
       "      <th>Amelie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User 1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Matrix  Alien  Serenity  Casablanca  Amelie\n",
       "User 1     1.0    1.0       1.0         0.0     0.0\n",
       "User 2     3.0    3.0       3.0        -0.0    -0.0\n",
       "User 3     4.0    4.0       4.0         0.0    -0.0\n",
       "User 4     5.0    5.0       5.0        -0.0    -0.0\n",
       "User 5     0.0    2.0      -0.0         4.0     4.0\n",
       "User 6     0.0    0.0      -0.0         5.0     5.0\n",
       "User 7     0.0    1.0      -0.0         2.0     2.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform SVD for 3 concepts\n",
    "u, s, vh = np.linalg.svd(u_t_m, full_matrices=False)\n",
    "print(\"U of size\", u[:,:3].shape, \":\")\n",
    "print(u[:,:3].astype(np.float16))\n",
    "print(\"Singular values:\")\n",
    "print(s.astype(np.float16)[:3])\n",
    "print(\"as a matrix:\")\n",
    "print(np.diag(s[:3]).astype(np.float16))\n",
    "print(\"V of size\", vh[:3,:].shape, \":\")\n",
    "print(vh[:3,:].astype(np.float16))\n",
    "\n",
    "# reconstruct the user-to-movie matrix\n",
    "A_aprox = u[:,:3] @ np.diag(s[:3]) @ vh[:3,:]\n",
    "A_aprox_df = pd.DataFrame(A_aprox.astype(np.float16), columns=['Matrix', 'Alien', 'Serenity', 'Casablanca', 'Amelie'],\n",
    "                        index=['User 1', 'User 2','User 3', 'User 4', 'User 5', 'User 6', 'User 7'])\n",
    "print(\"reconstruction of user-to-movie:\")\n",
    "A_aprox_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/tut_03_svd_3.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img src=\"https://img.icons8.com/color/96/000000/popcorn.png\" style=\"height:50px;display:inline\"> <a href=\"https://www.youtube.com/watch?v=P5mlg91as1c\">Great video from Stanford explaining SVD with the same example</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img src=\"https://img.icons8.com/dusk/64/000000/prize.png\" style=\"height:50px;display:inline\"> Credits\n",
    "* Icons from <a href=\"https://icons8.com/\">Icon8.com</a> - https://icons8.com\n",
    "* Datasets from <a href=\"https://www.kaggle.com/\">Kaggle</a> - https://www.kaggle.com/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
