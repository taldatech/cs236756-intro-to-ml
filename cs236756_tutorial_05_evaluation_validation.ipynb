{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img src=\"https://img.icons8.com/dusk/64/000000/mind-map.png\" style=\"height:50px;display:inline\"> CS 236756 - Technion - Intro to Machine Learning\n",
    "#### Tal Daniel\n",
    "## Tutorial 05 - Evaluation & Cross-Validation\n",
    "\n",
    "### <img src=\"https://img.icons8.com/bubbles/50/000000/checklist.png\" style=\"height:50px;display:inline\"> Agenda\n",
    "\n",
    "* Motivation\n",
    "* Metrics for Classifier's Evaluation\n",
    "* Methods for Classifier's Evaluation\n",
    "    * Holdout\n",
    "    * K-Fold Cross-Validation\n",
    "    * Stratification\n",
    "    * Leave-one-out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img src=\"https://img.icons8.com/dusk/64/000000/confetti.png\" style=\"height:50px;display:inline\"> Motivation - Why Evaluate Classifier's Generalization Ability?\n",
    "\n",
    "It is important to evaluate the classifier generalization performance in order to:\n",
    "* Determine whether to employ/distribute the classifier\n",
    "* Compare classifiers (even compare the same type of classifiers, but with different parameters)\n",
    "* Optimize the classifier to perform better on unseen data\n",
    "\n",
    "### <img src=\"https://img.icons8.com/bubbles/50/000000/info.png\" style=\"height:50px;display:inline\"> What Do We Need To Do That?\n",
    "The first question the needs to be asked, is what preparations are needed in order to evaluate a trained model. \n",
    "\n",
    "* **Train-Test Separation** - The *naive* approach is seprating the data into train set and test set, that is, taking a portion of the data for training the model (usually about 80% of the dataset) and save another portion, that the model **has not seen** in order to test the model's performance. This is called the test set (usually about 20% of the dataset).\n",
    "\n",
    "* Note: Scikit-learn has a function we can use called `train_test_split` that makes it easy for us to split our dataset into training and testing data.\n",
    "\n",
    "How do we make sure the separation is fair and that each set (train and test) is a good representation of the data distribution?\n",
    "\n",
    "* **Shuffling** - Shuffling the data serves the purpose of reducing variance and making sure that models remain general and overfit less. The popular case where shuffling is very important is when the data is sorted by their class/target. By shuffling we add randomness that assures that the training/test/validation sets are representative of the overall distribution of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for the tutorial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>862722</td>\n",
       "      <td>B</td>\n",
       "      <td>6.981</td>\n",
       "      <td>13.43</td>\n",
       "      <td>43.79</td>\n",
       "      <td>143.5</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.07568</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.54</td>\n",
       "      <td>50.41</td>\n",
       "      <td>185.2</td>\n",
       "      <td>0.1584</td>\n",
       "      <td>0.1202</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2932</td>\n",
       "      <td>0.09382</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>903554</td>\n",
       "      <td>B</td>\n",
       "      <td>12.100</td>\n",
       "      <td>17.72</td>\n",
       "      <td>78.07</td>\n",
       "      <td>446.2</td>\n",
       "      <td>0.10290</td>\n",
       "      <td>0.09758</td>\n",
       "      <td>0.04783</td>\n",
       "      <td>0.03326</td>\n",
       "      <td>...</td>\n",
       "      <td>25.80</td>\n",
       "      <td>88.33</td>\n",
       "      <td>559.5</td>\n",
       "      <td>0.1432</td>\n",
       "      <td>0.1773</td>\n",
       "      <td>0.1603</td>\n",
       "      <td>0.06266</td>\n",
       "      <td>0.3049</td>\n",
       "      <td>0.07081</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>91805</td>\n",
       "      <td>B</td>\n",
       "      <td>8.571</td>\n",
       "      <td>13.10</td>\n",
       "      <td>54.53</td>\n",
       "      <td>221.3</td>\n",
       "      <td>0.10360</td>\n",
       "      <td>0.07632</td>\n",
       "      <td>0.02565</td>\n",
       "      <td>0.01510</td>\n",
       "      <td>...</td>\n",
       "      <td>18.45</td>\n",
       "      <td>63.30</td>\n",
       "      <td>275.6</td>\n",
       "      <td>0.1641</td>\n",
       "      <td>0.2235</td>\n",
       "      <td>0.1754</td>\n",
       "      <td>0.08512</td>\n",
       "      <td>0.2983</td>\n",
       "      <td>0.10490</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>911366</td>\n",
       "      <td>B</td>\n",
       "      <td>11.620</td>\n",
       "      <td>18.18</td>\n",
       "      <td>76.38</td>\n",
       "      <td>408.8</td>\n",
       "      <td>0.11750</td>\n",
       "      <td>0.14830</td>\n",
       "      <td>0.10200</td>\n",
       "      <td>0.05564</td>\n",
       "      <td>...</td>\n",
       "      <td>25.40</td>\n",
       "      <td>88.14</td>\n",
       "      <td>528.1</td>\n",
       "      <td>0.1780</td>\n",
       "      <td>0.2878</td>\n",
       "      <td>0.3186</td>\n",
       "      <td>0.14160</td>\n",
       "      <td>0.2660</td>\n",
       "      <td>0.09270</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.990</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>915452</td>\n",
       "      <td>B</td>\n",
       "      <td>16.300</td>\n",
       "      <td>15.70</td>\n",
       "      <td>104.70</td>\n",
       "      <td>819.8</td>\n",
       "      <td>0.09427</td>\n",
       "      <td>0.06712</td>\n",
       "      <td>0.05526</td>\n",
       "      <td>0.04563</td>\n",
       "      <td>...</td>\n",
       "      <td>17.76</td>\n",
       "      <td>109.80</td>\n",
       "      <td>928.2</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.1361</td>\n",
       "      <td>0.1947</td>\n",
       "      <td>0.13570</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>0.07230</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>87930</td>\n",
       "      <td>B</td>\n",
       "      <td>12.470</td>\n",
       "      <td>18.60</td>\n",
       "      <td>81.09</td>\n",
       "      <td>481.9</td>\n",
       "      <td>0.09965</td>\n",
       "      <td>0.10580</td>\n",
       "      <td>0.08005</td>\n",
       "      <td>0.03821</td>\n",
       "      <td>...</td>\n",
       "      <td>24.64</td>\n",
       "      <td>96.05</td>\n",
       "      <td>677.9</td>\n",
       "      <td>0.1426</td>\n",
       "      <td>0.2378</td>\n",
       "      <td>0.2671</td>\n",
       "      <td>0.10150</td>\n",
       "      <td>0.3014</td>\n",
       "      <td>0.08750</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>913063</td>\n",
       "      <td>B</td>\n",
       "      <td>12.450</td>\n",
       "      <td>16.41</td>\n",
       "      <td>82.85</td>\n",
       "      <td>476.7</td>\n",
       "      <td>0.09514</td>\n",
       "      <td>0.15110</td>\n",
       "      <td>0.15440</td>\n",
       "      <td>0.04846</td>\n",
       "      <td>...</td>\n",
       "      <td>21.03</td>\n",
       "      <td>97.82</td>\n",
       "      <td>580.6</td>\n",
       "      <td>0.1175</td>\n",
       "      <td>0.4061</td>\n",
       "      <td>0.4896</td>\n",
       "      <td>0.13420</td>\n",
       "      <td>0.3231</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>8610637</td>\n",
       "      <td>M</td>\n",
       "      <td>18.050</td>\n",
       "      <td>16.15</td>\n",
       "      <td>120.20</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>0.10650</td>\n",
       "      <td>0.21460</td>\n",
       "      <td>0.16840</td>\n",
       "      <td>0.10800</td>\n",
       "      <td>...</td>\n",
       "      <td>18.91</td>\n",
       "      <td>150.10</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>0.1478</td>\n",
       "      <td>0.5634</td>\n",
       "      <td>0.3786</td>\n",
       "      <td>0.21020</td>\n",
       "      <td>0.3751</td>\n",
       "      <td>0.11080</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>8812877</td>\n",
       "      <td>M</td>\n",
       "      <td>15.750</td>\n",
       "      <td>20.25</td>\n",
       "      <td>102.60</td>\n",
       "      <td>761.3</td>\n",
       "      <td>0.10250</td>\n",
       "      <td>0.12040</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.06462</td>\n",
       "      <td>...</td>\n",
       "      <td>30.29</td>\n",
       "      <td>125.90</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>0.1552</td>\n",
       "      <td>0.4480</td>\n",
       "      <td>0.3976</td>\n",
       "      <td>0.14790</td>\n",
       "      <td>0.3993</td>\n",
       "      <td>0.10640</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "101   862722         B        6.981         13.43           43.79      143.5   \n",
       "394   903554         B       12.100         17.72           78.07      446.2   \n",
       "525    91805         B        8.571         13.10           54.53      221.3   \n",
       "469   911366         B       11.620         18.18           76.38      408.8   \n",
       "0     842302         M       17.990         10.38          122.80     1001.0   \n",
       "508   915452         B       16.300         15.70          104.70      819.8   \n",
       "204    87930         B       12.470         18.60           81.09      481.9   \n",
       "485   913063         B       12.450         16.41           82.85      476.7   \n",
       "77   8610637         M       18.050         16.15          120.20     1006.0   \n",
       "223  8812877         M       15.750         20.25          102.60      761.3   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "101          0.11700           0.07568         0.00000              0.00000   \n",
       "394          0.10290           0.09758         0.04783              0.03326   \n",
       "525          0.10360           0.07632         0.02565              0.01510   \n",
       "469          0.11750           0.14830         0.10200              0.05564   \n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "508          0.09427           0.06712         0.05526              0.04563   \n",
       "204          0.09965           0.10580         0.08005              0.03821   \n",
       "485          0.09514           0.15110         0.15440              0.04846   \n",
       "77           0.10650           0.21460         0.16840              0.10800   \n",
       "223          0.10250           0.12040         0.11470              0.06462   \n",
       "\n",
       "        ...       texture_worst  perimeter_worst  area_worst  \\\n",
       "101     ...               19.54            50.41       185.2   \n",
       "394     ...               25.80            88.33       559.5   \n",
       "525     ...               18.45            63.30       275.6   \n",
       "469     ...               25.40            88.14       528.1   \n",
       "0       ...               17.33           184.60      2019.0   \n",
       "508     ...               17.76           109.80       928.2   \n",
       "204     ...               24.64            96.05       677.9   \n",
       "485     ...               21.03            97.82       580.6   \n",
       "77      ...               18.91           150.10      1610.0   \n",
       "223     ...               30.29           125.90      1088.0   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "101            0.1584             0.1202           0.0000   \n",
       "394            0.1432             0.1773           0.1603   \n",
       "525            0.1641             0.2235           0.1754   \n",
       "469            0.1780             0.2878           0.3186   \n",
       "0              0.1622             0.6656           0.7119   \n",
       "508            0.1354             0.1361           0.1947   \n",
       "204            0.1426             0.2378           0.2671   \n",
       "485            0.1175             0.4061           0.4896   \n",
       "77             0.1478             0.5634           0.3786   \n",
       "223            0.1552             0.4480           0.3976   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \\\n",
       "101               0.00000          0.2932                  0.09382   \n",
       "394               0.06266          0.3049                  0.07081   \n",
       "525               0.08512          0.2983                  0.10490   \n",
       "469               0.14160          0.2660                  0.09270   \n",
       "0                 0.26540          0.4601                  0.11890   \n",
       "508               0.13570          0.2300                  0.07230   \n",
       "204               0.10150          0.3014                  0.08750   \n",
       "485               0.13420          0.3231                  0.10340   \n",
       "77                0.21020          0.3751                  0.11080   \n",
       "223               0.14790          0.3993                  0.10640   \n",
       "\n",
       "     Unnamed: 32  \n",
       "101          NaN  \n",
       "394          NaN  \n",
       "525          NaN  \n",
       "469          NaN  \n",
       "0            NaN  \n",
       "508          NaN  \n",
       "204          NaN  \n",
       "485          NaN  \n",
       "77           NaN  \n",
       "223          NaN  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's load the cancer dataset, shuffle it and  speratre into train and test set\n",
    "dataset = pd.read_csv('./datasets/cancer_dataset.csv')\n",
    "# print the number of rows in the data set\n",
    "number_of_rows = len(dataset)\n",
    "num_train = int(0.8 * number_of_rows)\n",
    "# reminder, the data looks like this\n",
    "dataset.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training samples: 455, total test samples: 114\n"
     ]
    }
   ],
   "source": [
    "# we will take the first 2 features as our data (X) and the diagnosis as labels (y)\n",
    "x = dataset[['radius_mean', 'texture_mean']].values\n",
    "y = dataset['diagnosis'].values == 'M'  # 1 for Malignant, 0 for Benign\n",
    "# shuffle\n",
    "rand_gen = np.random.RandomState(0)\n",
    "shuffled_indices = rand_gen.permutation(np.arange(len(x)))\n",
    "\n",
    "x_train = x[shuffled_indices[:num_train]]\n",
    "y_train = y[shuffled_indices[:num_train]]\n",
    "x_test = x[shuffled_indices[num_train:]]\n",
    "y_test = y[shuffled_indices[num_train:]]\n",
    "\n",
    "print(\"total training samples: {}, total test samples: {}\".format(num_train, number_of_rows - num_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img src=\"https://img.icons8.com/dusk/64/000000/rating.png\" style=\"height:50px;display:inline\"> Metrics for Classifier's Evaluation\n",
    "Different ML tasks use different metrics to measure the models' performance, we will introduce several of them, but there are more, and sometimes there are tasks that require hand-crafted metrics (for example, an NLP tasks of translating sentences from Chinese to English is measured by the BLEU score, which is a linguistic measure of language coherence).\n",
    "\n",
    "Throught this part, we will use the terms: True Positive (TP), False Positive (FP), True Negative (TN), False Negative (FN) which are demonstrated below:\n",
    "<img src=\"./assets/tut_05_tp_tf.jpg\" style=\"height:400px\">\n",
    "\n",
    "* **Accuracy** - $\\frac{TP + TN}{P + N}$\n",
    "    * In simple words: how many did we get *right* out of all of the dataset?\n",
    "    * When not to use *accuracy*?\n",
    "        * When dealing with *skewed* datasets (i.e., when some classes/labels are more frequent than others). \n",
    "* **Error** - $\\frac{FP + FN}{P + N}$\n",
    "    * In simple words: how many did we get *wrong* out of all of the dataset?\n",
    "* **Precision** - $\\frac{TP}{TP + FP}$\n",
    "    * In simple words: out of all the samples we calssified as *positive*, how many of them we got *right*. The accuracy of positive predictions.\n",
    "    * **Always** calculated along with **Recall**\n",
    "* **Recall (TP Rate, Sensitivity)** - $\\frac{TP}{P} = \\frac{TP}{TP + FN}$\n",
    "    * In simple words: out of all the *positive* samples, how many of them we got *right*. \n",
    "    * **Always** calculated along with **Precision**\n",
    "* **FP Rate** - $\\frac{FP}{N} = \\frac{FP}{FP + TN}$\n",
    "    * In simple words: out of all the *negative* samples, how many of them we got *wrong*, or, the ratio of negative instances that are incorrectly classified as positive.\n",
    "   \n",
    "### Quick Examples\n",
    "   * A classifier that is trained to detect videos that are safe for kids. You would probably prefer a classifier that rejects many good videos (low recall) but keeps only safe ones (high precision), rather than a classifier that has a much higher recall but lets a few really bad videos.\n",
    "   * A classifier trained to detect shoplifters on surveillance images: it is probably fine if your classifier has only 30% precision as long as it has 99% recall (almost all shoplifters will get caught. but a lot of false alarms).\n",
    "   \n",
    "### <img src=\"https://img.icons8.com/dusk/64/000000/classroom.png\" style=\"height:50px;display:inline\"> Example - Naive Classifier Evaluation on the Breast Cancer Dataset\n",
    "Let's create a classifier that classifies new samples by the label probability it has seen in the train set. That is, if it has seen 30% Malignant labels, then with probability 0.3 a new sample is classified as malignant.\n",
    "\n",
    "We will evaluate using the above metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M prob: 0.369, B prob: 0.631\n",
      "accuracy: 0.553 or 55.263 %\n",
      "error: 0.447 or 44.737 %\n",
      "precision: 0.405 or 40.541 %\n",
      "recall: 0.341 or 34.091 %\n",
      "FP Rate: 0.314 or 31.429 %\n"
     ]
    }
   ],
   "source": [
    "# probability to tag as malignat\n",
    "m_prob = np.sum(y_train) / len(y_train)\n",
    "# probability to tag as benign\n",
    "b_prob = 1 - m_prob\n",
    "print(\"M prob: {:.3f}, B prob: {:.3f}\".format(m_prob, b_prob))\n",
    "\n",
    "# now let's classify the test set\n",
    "# since we don't look at the data at all we can just randomly sample Ms and Bs in the size of the test set\n",
    "y_test_pred = np.random.choice([True, False], size=(len(y_test)), p=[m_prob, b_prob])\n",
    "\n",
    "# let's evaluate\n",
    "accuracy = np.sum(y_test == y_test_pred) / len(y_test)\n",
    "print(\"accuracy: {:.3f} or {:.3f} %\".format(accuracy, accuracy * 100))\n",
    "error = np.sum(y_test != y_test_pred) / len(y_test)\n",
    "print(\"error: {:.3f} or {:.3f} %\".format(error, error * 100))\n",
    "precision = np.sum(y_test_pred[y_test]) / np.sum(y_test_pred)\n",
    "print(\"precision: {:.3f} or {:.3f} %\".format(precision, precision * 100))\n",
    "recall = np.sum(y_test_pred[y_test]) / np.sum(y_test)\n",
    "print(\"recall: {:.3f} or {:.3f} %\".format(recall, recall * 100))\n",
    "fp_rate =  np.sum(y_test_pred[~y_test]) / np.sum(~y_test)\n",
    "print(\"FP Rate: {:.3f} or {:.3f} %\".format(fp_rate, fp_rate * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.405 or 40.541 %\n",
      "recall: 0.341 or 34.091 %\n"
     ]
    }
   ],
   "source": [
    "# using scikit-learn\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "print(\"precision: {:.3f} or {:.3f} %\".format(precision, precision * 100))\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "print(\"recall: {:.3f} or {:.3f} %\".format(recall, recall * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <img src=\"https://img.icons8.com/dusk/64/000000/planner.png\"  style=\"height:50px;display:inline\"> Confusion Matrix Revisited\n",
    "A better way to evaluate the performance of a calssifier is the look at the *confusion matrix*. Each row in a confusion matrix represents an actual calss. A perfect classifier would have only true positives and true negatives, so its confusion matrix would have non-zeros values only on its main diagonal.\n",
    "<img src=\"./assets/tut_05_conf_mat.jpg\" style=\"height:200px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Pos</th>\n",
       "      <th>Predicted Neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Pos</th>\n",
       "      <td>48</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Neg</th>\n",
       "      <td>29</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted Pos  Predicted Neg\n",
       "Actual Pos             48             22\n",
       "Actual Neg             29             15"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using scikit-learn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_test, y_test_pred)\n",
    "conf_mat_df = pd.DataFrame(conf_mat, columns=['Predicted Pos', 'Predicted Neg'], index=['Actual Pos', 'Actual Neg'])\n",
    "conf_mat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <img src=\"https://img.icons8.com/ios/100/000000/battle.png\" style=\"height:50px;display:inline\"> Precision/Recall Tradeoff\n",
    "**Increasing precision reduces recall, and vice versa.** It is often convenient to combine them into a single metric called the $F_1$ score.\n",
    "\n",
    "### <img src=\"https://img.icons8.com/dusk/64/000000/f.png\" style=\"height:50px;display:inline\"> The $F_1$ Score\n",
    "It is the *harmonic mean* of precision and recall.\n",
    "$$F_1 = \\frac{2}{\\frac{1}{precision} + \\frac{1}{recall}} = 2 \\times \\frac{precision \\times recall}{precision + recall} = \\frac{TP}{TP + \\frac{FN + FP}{2}} $$\n",
    "Whereas the regular mean treats all values equally , the harmonic mean gives much more weight to **low values**. As a result, the classifier will only get a high $F_1$ score if both recall and precision are high.\n",
    "\n",
    "The $F_1$ score favors classifiers that have similar precision and recall. This is not always what we want, as seen in the \"Quick Examples\" above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.370\n",
      "f1 score (scikit): 0.370\n"
     ]
    }
   ],
   "source": [
    "# calculating the f1 score\n",
    "f_1_score = 2 * precision * recall / (precision + recall)\n",
    "print(\"f1 score: {:.3f}\".format(f_1_score))\n",
    "# using scikit-learn\n",
    "from sklearn.metrics import f1_score\n",
    "f_1_score = f1_score(y_test, y_test_pred)\n",
    "print(\"f1 score (scikit): {:.3f}\".format(f_1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img src=\"https://img.icons8.com/clouds/100/000000/combo-chart.png\" style=\"height:50px;display:inline\"> Methods for Classifier's Evaluation\n",
    "So far we have separated our data to a train set and *test set* to evaluate our classifier. This is also called **hold-out** method.\n",
    "\n",
    "Let's list the ways we can estimate the metrics for a certain classifier:\n",
    "* **Training Data**\n",
    "* **Independent Test Data** (different from hold-out)\n",
    "* **Hold-Out Method**\n",
    "* **$K$-fold Cross-Validation**\n",
    "* **Leave-One-Out Method**\n",
    "* **Bootstrap Method**\n",
    "* And more...\n",
    "\n",
    "We will now present some of them that you will use.\n",
    "\n",
    "### <img src=\"https://img.icons8.com/dusk/64/000000/dumbbell.png\" style=\"height:50px;display:inline\"> Estimation with Training Data\n",
    "<img src=\"./assets/tut_05_train.jpg\" style=\"height:100px\">\n",
    " * The accuracy/error estimates ont the *training* data **are not** good indicators of performance on future data!\n",
    " * The reason: new data will probably not be exactly the same as the training data.\n",
    " * The accuracy/error estimates on the training data measure the degree of calssifier's **underfitting** or **overfitting**.\n",
    " * A typical learning curve usually looks like this: <img src=\"./assets/tut_05_overfit.png\" style=\"height:200px\">\n",
    "(image from <a href=\"http://mlwiki.org/index.php/Overfitting\">mlwiki.org</a>)\n",
    "\n",
    "### <img src=\"https://img.icons8.com/bubbles/100/000000/test-passed.png\" style=\"height:50px;display:inline\"> Estimation with Independent Test Data\n",
    "<img src=\"./assets/tut_05_test.jpg\" style=\"height:100px\">\n",
    "* Estimation with independent test data is used when we have plenty of data and there is **a natural way to generating this data**, that is, there is no need to separate the the train data.\n",
    "* For example, we wish to learn a certainn function, like $f(x) = x^2$, we can generate how many samples we want and we are not bounded to a certain dataset.\n",
    "* In most ML tasks, we have no natural way of forming data, and we are limited to the data given to us, which is why it is more common to use hold-out.\n",
    "\n",
    "### <img src=\"https://img.icons8.com/nolan/64/000000/separate-document.png\" style=\"height:50px;display:inline\"> Hold-Out Method\n",
    "<img src=\"./assets/tut_05_holdout.jpg\" style=\"height:200px\">\n",
    "* The hold-out method **splits** the data into training data and test data. Then, we build a classifier using the train set and test it using the test set.\n",
    "* The hold-out method is usually used when we have thousands of instances, including several hundred instances from each class.\n",
    "* Scikit-learn has a built in function that you can use to split the data: `from sklearn.model_selection import train_test_split`\n",
    "\n",
    "### <img src=\"https://img.icons8.com/bubbles/100/000000/more.png\" style=\"height:50px;display:inline\"> Train-Validation-Test Split\n",
    "Let's say you have a dataset which you separated into *train* set and *test* set. You want to train a classifier that has hyper-parameters (parameters that are not trained, but are user-selected before the training) that you have to tune. For example, in the classifier \"K-Nearest Neighbours\" you need to choose $K$, the number of nearest neighbours needed to perform classification, or in \"Stochastic Gradient Descent\", you need to choose the learning rate (which is a continuous value, like 0.0001). Would it be fair to train the classifier on the train set for each hyper-parameter and then test it on the test set and finally selcting the best hyper-parameters based on the performance on the test set? **NO!**\n",
    "\n",
    "It is like taking an open-material exam, but instead of bringing all of the material, you bring only the material relevant to the questions asked in the exam. It is sort of cheating. That is why we seperate into 3 sets:\n",
    "* **Tran Set** - from which the model learns\n",
    "* **Validation Set** - on which the hyper-parameters are tuned\n",
    "* **Test Set** - untouched samples on which you test the generalization ability of the model. This set has **never** been seen by the model.\n",
    "\n",
    "<img src=\"./assets/tut_05_validation.jpg\" style=\"height:300px\">\n",
    "\n",
    "### <img src=\"https://img.icons8.com/cotton/64/000000/full-battery.png\" style=\"height:50px;display:inline\"> Making the Most of the Data\n",
    "* Once evaluation is complete and you are satisfied with the model, *all* the data can be used to build the final classifier\n",
    "* Generally, the **larger the training data** the **better the classifier**.\n",
    "* The **larger the test set** the **more accurate** the error estimate.\n",
    "\n",
    "### <img src=\"https://img.icons8.com/clouds/100/000000/color-dropper.png\" style=\"height:50px;display:inline\"> Stratification\n",
    "* The *holdout* method reserves a certain amount for testing and uses the remainder for training.\n",
    "* For **\"unbalanced\"/skewed** datasets, samples might not be representative.\n",
    "    * Few or None instances of some classes\n",
    "* **Stratified Sampling**: balancing the data. If the dataset is not large enough, there is a risk of introducing a significant sampling *bias*. In *stratified sampling*, the population is divided into homogenous subgroups called *strata*, and the right number of instances is sampled from each stratum to guarantee that the test set is representative of the overall population.\n",
    "    * Makes sure that each class is represented with approximately equal proportions in both subsets.\n",
    "* For example, when a survey company decides to call 1,000 people to ask them a few questions, they don't just pick up randomly 1,000 people from a phone book. They try to ensure that these 1,000 people are representative of the whole population. In the US, the population is composed of 51.3% female and 48.7% men, so a well-conducted survey in the US would try to maintain this ratio in the samples - 513 female and 487 male.\n",
    "* In Scikit-learn - `from sklearn.model_selection import StratifiedShuffleSplit` - <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html\">Read More Here</a>\n",
    "\n",
    "### <img src=\"https://img.icons8.com/nolan/64/000000/delete-sign.png\" style=\"height:50px;display:inline\"> K-Fold Cross-Validation\n",
    "Seprating to validation and test sets is not very data efficient as we now allocate less data for training. In order to make better use of the data we use a technique called \"Cross Validation\". However, in this course we will always to this sepration regardless! (we'll use the train set for CV).\n",
    "Cross-validation is randomly splitting the data into $k$ groups. One of the groups is used as the test set and the rest are used as the training set. The model is trained on the training set and scored on the test set. Then the process is repeated until each unique group as been used as the test set. This method is also called \"K-Fold Cross Validation\".\n",
    "\n",
    "For example, for 5-fold cross validation, the dataset is split into 5 groups, and the model is trained and tested 5 separate times so each group gets a chance to be the test set. This can be seen in the image below.\n",
    "\n",
    "<img src=\"./assets/tut_05_kfold.jpeg\" style=\"height:250px\" />\n",
    "(image from Datacamp)\n",
    "\n",
    "Cross-validation is better than using the holdout method because the holdout method score is dependent on how the data is split into train, validation and test sets. Cross-validation gives the model an opportunity to test on multiple splits so we can get a better idea on how the model will perform on unseen data.\n",
    "\n",
    "**The steps:**\n",
    "1. Data is split into $k$ subsets of equal size.\n",
    "2. Each subset in turn is used for testing and the reaminder for training.\n",
    "3. The estimates are averaged to yield an overall estimate.\n",
    "\n",
    "**Implementation using Scikit-learn:**\n",
    "* `cross_val_score` - takes in a classifier, training data, $k$ (number of folds) and the scoring technique (\"accuracy\" for example). <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\">Read the Doc Here</a>\n",
    "* `StratifiedKFold` - if you need more control over the cross-validation process than provided in `cross_val_score`, it is possible to implement cross-validation yourself. The `StratifiedKFold` class performs stratified sampling to produce folds that contain a representative ratio of each class. <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html\">Read the Doc Here</a>\n",
    "\n",
    "**More on Cross-Validation:**\n",
    "* Standard method for evaluation: *stratified 10-fold cross validation*\n",
    "* Stratification reduces the estimate's *variance* (more confidence in the output)\n",
    "* An even better method: **repeated** stratified cross-validation\n",
    "    * For example, 10-fold cross-validation is repeated 10 times and the results are averaged (reduces the variance).\n",
    "* Which dataset should we use for the $K$-Fold Cross Validation (Train, Test, Validation)?\n",
    "    * The **test set** - must be untouched, put aside. Don't use it for ANY purpose other than testing.\n",
    "    * The **validation set** - used to test performances of the models at various stages of the model development (like tuning the hyper-parameters of the model)\n",
    "    * The **train set** - used for training, including cross-validation. USE ONLY THIS FOR CV!\n",
    "    \n",
    "### <img src=\"https://img.icons8.com/doodle/100/000000/big-puzzle--v1.png\" style=\"height:50px;display:inline\"> Leave-One-Out Cross-Validation\n",
    "* A particular form of cross-validation where the number of folds = number of training instances\n",
    "    * That is, for training set of size $n$, the classifier is built $n$ times\n",
    "* Makes best use of the data\n",
    "* Involves **no random subsampling**\n",
    "* Very computationally **expensive**\n",
    "* **Stratification is not possible** - it is a big disadvantage\n",
    "    * It *guarantees* a non-stratified sample because there is only one instance in the test set.\n",
    "* Extreme example - random datatset split equally into two classes:\n",
    "    * Best inducer predicts majority class\n",
    "    * 50% accuracy on fresh data\n",
    "    * Leave-One-Out CV estimate is 100% error!\n",
    "    \n",
    "#### Pre-proceesing steps on validation steps\n",
    "* Whatever data preparations steps done on the training data, should be able to be applied at the final test on unseen data.\n",
    "    * For example, if normalizing a feature with a mean, the mean is fixed at the data prep and **not recalculated**. Otherwise, a model that was trained and tested on data that used the former mean may not be adequate.\n",
    "* Data preparation steps are mostly based on descriptive statistics. So a **larger sample** that provides a **stable statistics** is an advantage.\n",
    "* By not using the validation set, we have a **better estimate of the \"true error\"**, which we measure by applying pre-processing steps to test data.\n",
    "* By using the validation set, we **separate the effect of the pre-processing** from that of the classifier.\n",
    "\n",
    "## <img src=\"https://img.icons8.com/color/96/000000/super-hero-female.png\" style=\"height:50px;display:inline\"> Classification Example - Breast Cancer - From Zero to Hero\n",
    "We will now demonstrate all that we have learned on the Breast Cancer dataset. For the purpose of the exercise, we will use a classifier called \"SGDClassifier\" (SVM using Stochastic Gradient Descent). You are not supposed to be familiar with it at this point of the course, you can read more about it <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\"></a>. We will use it as a black-box algorithm that gives us classification for a certain dataset.\n",
    "\n",
    "* We will only use *train* and *test* sets since the dataset has limited number of samples and since we are not going to tune the hyper-parameters of the model.\n",
    "* Each classifier has a **decision function** - for each instance, it computes a score and if that score is greater than some threshold, it assigns the instance to the positive class, or else it assigns it to the negative class (lowering the threshold usually leads to increase in *recall* and reduce in *precision*, and vice versa.\n",
    "* Finally, will briefly introduce the **ROC Curve**, as a tool to asses to performance of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-learn imports\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_recall_curve, roc_curve, roc_auc_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training samples: 455, total test samples: 114\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset\n",
    "# we will take the first 2 features as our data (X) and the diagnosis as labels (y)\n",
    "x = dataset[['radius_mean', 'texture_mean']].values\n",
    "y = dataset['diagnosis'].values == 'M'  # 1 for Malignat, 0 for Benign\n",
    "# x = scaler.fit_transform(x)\n",
    "# shuffle\n",
    "rand_gen = np.random.RandomState(0)\n",
    "shuffled_indices = rand_gen.permutation(np.arange(len(x)))\n",
    "\n",
    "x_train = x[shuffled_indices[:num_train]]\n",
    "y_train = y[shuffled_indices[:num_train]]\n",
    "x_test = x[shuffled_indices[num_train:]]\n",
    "y_test = y[shuffled_indices[num_train:]]\n",
    "\n",
    "# pre-process - standartization\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "print(\"total training samples: {}, total test samples: {}\".format(num_train, number_of_rows - num_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy in each fold:\n",
      "[0.82608696 0.86956522 0.84782609 0.91304348 0.89130435 0.82608696\n",
      " 0.91304348 0.82222222 0.88636364 0.88636364]\n",
      "mean training accuracy:\n",
      "0.8681906016688625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=92, shuffle=True,\n",
       "       tol=0.001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the classifier\n",
    "sgd_clf = SGDClassifier(random_state=92, max_iter=1000, tol=1e-3)  # we make the random state constant for reproducible results\n",
    "# train (fit) using cross validation\n",
    "k_folds = 10\n",
    "cross_val_scores = cross_val_score(sgd_clf, x_train, y_train, cv=k_folds, scoring='accuracy')\n",
    "print(\"accuracy in each fold:\")\n",
    "print(cross_val_scores)\n",
    "print(\"mean training accuracy:\")\n",
    "print(cross_val_scores.mean())\n",
    "\n",
    "# Now, fit the classifier to the train data\n",
    "sgd_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Pos</th>\n",
       "      <th>Predicted Neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Pos</th>\n",
       "      <td>62</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Neg</th>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted Pos  Predicted Neg\n",
       "Actual Pos             62              8\n",
       "Actual Neg              4             40"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "y_test_pred = sgd_clf.predict(x_test)\n",
    "# confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_test_pred)\n",
    "conf_mat_df = pd.DataFrame(conf_mat, columns=['Predicted Pos', 'Predicted Neg'], index=['Actual Pos', 'Actual Neg'])\n",
    "conf_mat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 89.474 % , f1 score: 0.870\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "accuracy = np.sum(y_test == y_test_pred) / len(y_test)\n",
    "# f1 score\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "print(\"accuracy: {:.3f} % , f1 score: {:.3f}\".format(accuracy * 100, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.3631803]\n"
     ]
    }
   ],
   "source": [
    "# let's get the scores for some instance\n",
    "y_scores = sgd_clf.decision_function([x_train[0]])\n",
    "# for SGDClssifier, the default threshold is 0, anything below is calssified as negative and else positive\n",
    "print(y_scores)\n",
    "# let's see the effect of the threshold on the training data\n",
    "y_scores = cross_val_predict(sgd_clf, x_train, y_train, cv=k_folds, method=\"decision_function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's plot and see the effect\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train, y_scores)\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "ax.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
    "ax.set_xlabel(\"Threshold\")\n",
    "ax.set_title(\"Precision/Recall Tradeoff\")\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "ax.set_ylim([0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <img src=\"https://img.icons8.com/dusk/64/000000/rock-music.png\" style=\"height:50px;display:inline\"> The ROC Curve\n",
    "The *receiver operating characteristic* (ROC) curve is another common tool used with binary classifiers. It is very similar to the precision/recall curve, but uses the True Positive Rate (TPR, another name for Recall) vs. the False Positive Rate (FPR, the ratio of negtaive instances that are incorrectly classified as positive) we saw in the beginning of the tutorial.\n",
    "* Note: The FPR is equal to $1 - TNR$ (true negative rate, or, *specifity*)\n",
    "* The ROC curve plots *sensitivity* (recall) vs. 1 - *specifity*.\n",
    "* **TPR/FPR Tradeoff**: The higher the TPR (recall) the more *false positive* (FPR) the classifier produces.\n",
    "* To compare classifiers - measure the *area under the curve* (AUC). A perfect classifier will have a ROC AUC equal to 1, whereas a purely random one will have a 0.5 AUC.\n",
    "* **Precision/Recall curve vs ROC curve**: if the positive class is rare, or you care more about the false positive than the false negative use **Precision/Recall**. Otherwise, use the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.927\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_train, y_scores)\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train, y_scores)\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(fpr, tpr, linewidth=2)\n",
    "ax.plot([0,1], [0,1], 'k--') # random classifier\n",
    "ax.set_xlabel(\"False Positive Rate (FPR)\")\n",
    "ax.set_ylabel(\"True Positive Rate(TPR=Recall)\")\n",
    "ax.set_title(\"ROC Curve\")\n",
    "ax.grid()\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "roc_auc = roc_auc_score(y_train, y_scores)\n",
    "print(\"ROC AUC Score: {:.3f}\".format(roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img src=\"https://img.icons8.com/dusk/64/000000/prize.png\" style=\"height:50px;display:inline\"> Credits\n",
    "* Icons from <a href=\"https://icons8.com/\">Icon8.com</a> - https://icons8.com\n",
    "* Datasets from <a href=\"https://www.kaggle.com/\">Kaggle</a> - https://www.kaggle.com/\n",
    "* Examples and code snippets were taken from <a href=\"http://shop.oreilly.com/product/0636920052289.do\">\"Hands-On Machine Learning with Scikit-Learn and TensorFlow\"</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
